\section{Symplectic MOR with weighted inner product} \label{sec:normmor}

In this section we combine the concept of model reduction with a weighted inner product, discussed in \cref{sec:mor.1}, with the symplectic model reduction discussed in \cref{sec:mor.2}. We will argue that the new method can be viewed as a natural extension of the original symplectic method. Finally, we generalize the greedy method for the symplectic basis generation, and the symplectic model reduction of nonlinear terms to be compatible with any non-degenerate weighted inner product.

\subsection{Generalization of the symplectic projection} \label{sec:normmor.1}
As discussed in \cref{sec:mor.1}, the error analysis of methods for solving partial differential equations often requires the use of a weighted inner product. This is particularly important when dealing with Hamiltonian systems, where the system energy can induce a norm that is fundamental to the dynamics of the system.

Consider a Hamiltonian system of the form (\ref{eq:mor.8}) together with the weighted inner product defined in (\ref{eq:mor.3}) with $m=2n$. Also suppose that the solution $z$ to (\ref{eq:mor.8}) is well approximated by a $2k$ dimensional symplectic subspace with the basis matrix $A$. We seek to construct a projection operator that minimizes the projection error with respect to the $X$-norm while preserving the symplectic dynamics of (\ref{eq:mor.8}) in the projected space. Consider the operator $P: \mathbb R^{2n} \to \mathbb R^{2n}$ be defined as
%\begin{align*}
%\| X^{1/2} S - X^{1/2} A X^{1/2} A ^+ X^{1/2} S \|_F^2 = \| X^{1/2} S - X^{1/2} A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X S \|_F^2.
%\end{align*}
\begin{equation} \label{eq:normmor.1}
	P = A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X.
\end{equation}
It is easy to show that $P$ is idempotent if and only if
\begin{equation} \label{eq:normmor.2}
	\mathbb J_{2k}^T A^T X \mathbb J_{2n} X A = I_{2k},
\end{equation}
in which case $P$ is a projection operator onto colspan$(A)$. Suppose that $S$ is the snapshot matrix containing the time samples $\{z(t_i)\}_{i=1}^N$ of the solution to (\ref{eq:mor.8}). We seek to find the basis $A$ that minimizes the collective projection error of snapshots with respect to the $X$-norm,
\begin{equation} \label{eq:normmor.3}
\begin{aligned}
& \underset{A\in \mathbb{R}^{2n\times 2k}}{\text{minimize}}
& & \sum_{i=1}^N \| z(t_i) - P(z(t_i)) \|_X^2, \\
& \text{subject to}
& & \mathbb J_{2k}^T A^T X \mathbb J_{2n} X A = I_{2k}.
\end{aligned}
\end{equation}
By (\ref{eq:normmor.1}) we have
\begin{equation} \label{eq:normmor.4}
\begin{aligned}
	\sum_{i=1}^N \| z(t_i) - P(z(t_i)) \|_X^2 &= \sum_{i=1}^N \| z(t_i) - A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X z(t_i) \|_X^2 \\
	&= \sum_{i=1}^N \| X^{1/2}z(t_i) - X^{1/2} A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X z(t_i) \|_2^2 \\
	&= \| X^{1/2} S - X^{1/2} A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X S \|_F^2 \\
	&= \| \tilde S - \tilde A \tilde A ^+ \tilde S \|_F^2.
\end{aligned}
\end{equation}
Here $\tilde S = X^{1/2} S$, $\tilde A = X^{1/2} A$, and $\tilde A^+ = \mathbb J_{2k}^T \tilde A^T J_{2n}$ is the symplectic inverse of $\tilde A$ with respect to the skew-symmetric matrix $J_{2n} = X^{1/2} \mathbb J_{2n} X^{1/2}$. Note that the symplectic inverse in (\ref{eq:normmor.4}) is a generalization of the symplectic inverse introduced in \cref{sec:mor.2}. Therefore, we may use the same notation (the superscript $+$) for both. We summarized the properties of this generalization in \Cref{thm:2}. With this notation, the condition (\ref{eq:normmor.2}) turns into $\tilde A ^+ \tilde A = I_{2k}$ which is equivalent to $\tilde A ^T J_{2n} \tilde A = \mathbb J_{2k}$. In other words, this condition implies that $\tilde A$ has to be a $J_{2n}$-symplectic matrix. Finally we can rewrite the minimization (\ref{eq:normmor.3}) as
\begin{equation} \label{eq:normmor.5}
\begin{aligned}
& \underset{\tilde A\in \mathbb{R}^{2n\times 2k}}{\text{minimize}}
& & \| \tilde S - P^\text{symp}_{X,\tilde A}(\tilde S) \|_F, \\
& \text{subject to}
& & \tilde A^T J_{2n} \tilde A = \mathbb J_{2k}.
\end{aligned}
\end{equation}
where $P^\text{symp}_{X,\tilde A} = \tilde A \tilde A^+$ is the symplectic projection with respect to the $X$-norm onto the colspan($\tilde A$). At first glance, the minimization (\ref{eq:normmor.5}) might look similar to (\ref{eq:mor.13}). However, since $\tilde A$ is $J_{2n}$-symplectic, and the projection operator depends on $X$, we need to seek an alternative approach to find a near optimal solution to (\ref{eq:normmor.5}). 

As (\ref{eq:mor.13}), direct approaches to solving (\ref{eq:normmor.5}) are impractical. Furthermore, there are no SVD-type methods known to the authors, that solve (\ref{eq:normmor.5}). However, the greedy generation of the symplectic basis can be generalized to generate a near optimal basis $\tilde A$. The generalized greedy method is discussed in \cref{sec:normmor.2}.

Now suppose that a basis $A=X^{-1/2}\tilde A$, with $\tilde A$ solving (\ref{eq:normmor.5}), is available such that $z \approx Ay$ with $y\in \mathbb R^{2k}$, the expansion coefficients of $z$ in the basis of $A$. Using (\ref{eq:normmor.2}) we may write the reduced system to (\ref{eq:mor.8}) as
\begin{equation} \label{eq:normmor.6}
	\dot y = \mathbb J_{2k}^T A^T X \mathbb J_{2n} X \mathbb{J}_{2n} LAy + \mathbb J_{2k}^T A^T X \mathbb J_{2n} X \mathbb{J}_{2n} \nabla_z f(Ay).
\end{equation}
Since $(\mathbb J_{2k}^T A^T X \mathbb J_{2n} X) A = I_{2k}$, we may use the chain rule to write
\begin{equation} \label{eq:normmor.7}
	\nabla_z H(z) = ( \mathbb J_{2k}^T A^T X \mathbb J_{2n} X )^T \nabla_y H(Ay).
\end{equation}
\todo[inline]{Equation \cref{eq:normmor.7} is not quite correct because
$$\nabla_z H(Ay) = \nabla_z H(z)|_{z=Ay} \stackrel{\text{?}}{=} A^{+T} \nabla_y H(Ay)$$
is not valid. If it were true then
$$\nabla_z H(Ay) = A^{+T} \nabla_y H(Ay) = A^{+T} A^T \nabla_z H(Ay) = (AA^+)^T \nabla_z H(Ay)$$
which implies
$$(I- (AA^+)^T) \nabla_z H(Ay) = 0,$$
for all $Ay \in domain(\nabla_z H)$, which could only be true iff $AA^+ =I$ i.e. iff the projection is identity.

The other direction is clear because
$$\nabla_y H(Ay) = \nabla_y H(z)|_{z=Ay} =\nabla_y z^T \nabla_z H(z)|_{z=Ay} = A^T \nabla_z H(Ay)$$
by the virtue of the chain rule.

In case of $X=I$, one can still derive \cref{eq:normmor.7} using
$$\mathbb J_{2k}^T A^T \mathbb J_{2n} \mathbb{J}_{2n} =  \mathbb J_{2k} A^T.$$
But this doesn't generalize to the more general case of non uniform weighting.}
Finally, as $\nabla_z H(z) = Lz + \nabla_z f(z)$, the reduced system (\ref{eq:normmor.6}) becomes
\begin{equation} \label{eq:normmor.8}
\left\{
\begin{aligned}
	\dot y(t) &= J_{2k} A^T L A y + J_{2k} \nabla_y f(Ay), \\
	y(0) &= \mathbb J_{2k}^T A^T X \mathbb J_{2n} X z_0,
\end{aligned}
\right.
\end{equation}
where $J_{2k}=\tilde A^+ J_{2n} (\tilde A^+)^T$ is a skew-symmetric matrix. The system (\ref{eq:normmor.8}) is a generalized Hamiltonian system with the Hamiltonian defined as $\mathcal H(y) = \frac 1 2 y^TA^TLAy + f(Ay)$. Therefore, a Poisson integrator preserves the symplectic symmetry associated with (\ref{eq:normmor.8}).

We close this section by summarizing the properties of the symplectic inverse in the following theorem.
\begin{theorem} \label{thm:2}
Let $A\in \mathbb R^{2n\times 2k}$ be a $J_{2n}$-symplectic basis where $J_{2n}\in\mathbb R^{2n\times 2n}$ is a full rank and skew-symmetric matrix. Furthermore, suppose that $A^{+} = \mathbb{J}_{2k}^T A^T J_{2n}$ is the symplectic inverse. Then the following holds:
\begin{enumerate}
\item $A^+A = I_{2k}$.
\item $(A^+)^T$ is $J_{2n}^{-1}$-symplectic.
\item $\left(\left(\left(A^+\right)^T\right)^+\right)^T = A$.
\item Let $J_{2n}=X^{1/2}\mathbb J_{2n} X^{1/2}$. Then $A$ is ortho-normal with respect to the $X$-norm, if and only if $(A^+)^T$ is ortho-normal with respect to the $X^{-1}$-norm.
\end{enumerate}
\end{theorem}
\begin{proof}
It is straightforward to show all statements using the definition of a symplectic basis.
\end{proof}

\subsection{Stability Conservation} It is shown in \cite{doi:10.1137/140978922,doi:10.1137/17M1111991} that a Hamiltonian reduced system constructed by the projection $P^{\text{symp}}_{I,A}$ preserves the stability of stable equilibrium points of \cref{eq:mor.12}, and therefore, preserves the overall dynamics. In this section, we discuss that the stability of equilibrium points is also conserved using the projection operator $P^{\text{symp}}_{X,\tilde A}$.

\begin{proposition} \label{prop:new1}
\cite{bhatia2002stability} An equilibrium point $z_e\in \mathbb R^{2n}$ is Lyapunov stable if there exists a scalar function $W:\mathbb R^{2n} \to \mathbb R$ such that $\nabla W(z_e) = 0$, $\nabla^2 W(z_e)$ is positive definite, and that for any trajectory $z(t)$ defined in the neighborhood of $z_e$, we have $\frac{d}{dt} W(z(t))\leq 0$. Here $\nabla^2 W$ is the Hessian matrix of $W$, and $W$ is commonly referred to as a Lyapunov function.
\end{proposition}

It is shown in \cite{doi:10.1137/17M1111991} that the stable points of the Hamiltonian reduced system constructed using the projection $P^{\text{symp}}_{X,\tilde A}$ is Lyapunov stable. However, since the proof only requires the conservation of the Hamiltonian and the positive definiteness of $\mathcal H$, the proof also holds for generalized Hamiltonian reduced systems.

\begin{theorem}
\cite{doi:10.1137/17M1111991} Consider a Hamiltonian system of the form \cref{eq:mor.8} together with the reduced system \cref{eq:normmor.8}. Suppose that $z_e$ is an equilibrium point for \cref{eq:mor.8} and that $y_e = \tilde A ^+ X^{1/2} z_e$. If $H$ (or $-H$) is a Lyapunov function satisfying \cref{prop:new1}, then $z_e$ and $y_e$ are Lyapunov stable equilibrium points for \cref{eq:mor.8} and \cref{eq:normmor.8}, respectively.
\end{theorem}

\subsection{Greedy generation of a $J_{2n}$-symplectic basis} \label{sec:normmor.2}
In this section we modify the greedy algorithm introduced in \cref{sec:mor.3} to construct a $J_{2n}$-symplectic basis. Ortho-normalization is an essential step in greedy approaches to basis generation \cite{hesthaven2015certified,quarteroni2015reduced}. Here, we summarize a variation of the GS orthogonalization process, known as the \emph{symplectic GS} process.

Suppose that $\Omega_{J_{2n}}$ is a symplectic form defined on $\mathbb R^{2n}$ such that $\Omega_{J_{2n}}(x,y) = x^T J_{2n} y$, for all $x,y\in \mathbb R^{2n}$ and some full rank and skew-symmetric matrix $J_{2n} = X^{1/2} \mathbb J_{2n} X^{1/2}$. We would like to build a basis of size $2k+2$ in an iterative manner and start with some initial vector, e.g. $e_1 = z_0/\| z_0 \|_X$. It is known that a symplectic basis has an even number of basis vectors \cite{Marsden:2010:IMS:1965128}. We may take $Te_1$, where $T = X^{-1/2} \mathbb J_{2n}^{T}X^{1/2}$, as a candidate for the second basis vector. It is easily verified that $\tilde A_2=[e_1|Te_1]$ is $J_{2n}$-symplectic and consequently, $\tilde A_2$ is the first basis generated by the greedy approach. Next, suppose that $\tilde A_{2k} = [e_1|\dots|e_k|Te_1|\dots|Te_k]$ is generated in the $k$th step of the greedy method and $z\not \in \text{colspan}\left(\tilde A_{2k}\right)$ is provided. We aim to $J_{2n}$-orthogonalize $z$ with respect to the basis $\tilde A_{2k}$. This means we seek a coefficient vector $\alpha\in \mathbb R^{2k}$ such that
\begin{equation} \label{eq:normmor.9}
	\Omega_{J_{2n}}\left( z + \tilde A_{2k}\alpha ,  y \right) = 0,
\end{equation}
for all possible $y \in \text{colspan}(\tilde A_{2k})$. It is easily checked that \eqref{eq:normmor.9} has the unique solution $\alpha_i = -\Omega_{J_{2n}}(z,Te_i)$ for $i\leq k$ and $\alpha_i = \Omega_{J_{2n}}(z,e_i)$ for $i>k$, i.e., $z$ has a unique symplectic projection. If we take $\tilde z = z + \tilde A_{2k}\alpha$, then the next candidate pair of basis vectors are $e_{k+1} = \tilde z / \| \tilde z \|_X$ and $Te_{k+1}$. Finally, the basis generated at the $(k+1)$-th step of the greedy method is given by
\begin{equation} \label{eq:normmor.11}
	\tilde A_{2k+2} = [e_1|\dots|e_{k+1}|Te_1|\dots|Te_{k+1}].
\end{equation}
\Cref{thm:3} guarantees that the column vectors of $\tilde A_{2k+2}$ are linearly independent. Furthermore, it is checked easily that $\tilde A_{2k+2}$ is $J_{2n}$-symplectic. We note that the symplectic GS orthogonalization process is chosen due to its simplicity. However, in problems where there is a need for a large basis, this process might be impractical. In such cases, one may use a backward stable routine, e.g. the isotropic Arnoldi method or the isotropic Lanczos method \cite{doi:10.1137/S1064827500366434}.

It is well known that a symplectic basis, in general, is not norm bounded \cite{doi:10.1137/050628519}. The following theorem guarantees that the greedy method for generating a $J_{2n}$-symplectic basis yields a bounded basis.
\begin{theorem} \label{thm:3}
The basis generated by the greedy method for constructing a $J_{2n}$-symplectic basis is orthonormal with respect to the $X$-norm.
\end{theorem}
\begin{proof}
Let $\tilde A_{2k}=[e_1|\dots,e_k|Te_1|\dots|Te_k]$ be the $J_{2n}$-symplectic basis generated at the $k$th step of the greedy method. Using the fact that $\tilde A_{2k}$ is $J_{2n}$-symplectic, one can check that
\begin{equation} \label{eq:normmor.12}
	\left\langle e_i,e_j\right\rangle_X = \left\langle Te_i,Te_j\right\rangle_X = \Omega_{J_{2n}}(e_i,Te_j)=\delta_{i,j}, \quad i,j=1,\dots,k,	
\end{equation}
and
\begin{equation} \label{eq:normmor.13}
	\left\langle e_i,Te_j \right\rangle_X = \Omega_{J_{2n}}(e_i,e_j) = 0\quad i,j=1,\dots,k,
\end{equation}
where $\delta_{i,j}$ is the Kronecker delta function. This ensures that $\tilde A_{2k}^TX\tilde A_{2k} = I_{2k}$, i.e., $\tilde A_{2k}$ is an ortho-normal basis with respect to the $X$-norm.
\end{proof}
We note that if we take $X=I_{2n}$, then the greedy process generates a $\mathbb J_{2n}$- symplectic basis. With this choice, the greedy method discussed above becomes identical to the greedy process discussed in \cref{sec:mor.3}. Therefore, the symplectic model reduction with a weight matrix $X$ is indeed a generalization of the method discussed in \cref{sec:mor.2}.

We notice that $X^{1/2}$ does not explicitly appear in \cref{eq:normmor.8}. Therefore, it is desirable to compute $A_{2k} = X^{-1/2} \tilde A_{2k}$ without requiring the computation of the matrix square root of $X$. It is easily checked that the matrix $B_{2k}:=X^{1/2} \tilde A_{2k} = XA_{2k}$ is $\mathbb J_{2n}$-symplectic and orthonormal. Reformulation of condition \cref{eq:normmor.9} yields
\begin{equation} \label{eq:normmor.13.1}
	\Omega_{\mathbb J_{2n}}\left( w + B_{2k} \alpha, \bar y \right) = 0, \quad \forall \bar y \in \text{colspan}(B_{2k}),
\end{equation}
where $w = X^{1/2}z$. From \cref{eq:mor.14.1} we know that \cref{eq:normmor.13.1} has the unique solution $\alpha_i = - \Omega_{\mathbb J_{2n}}(z,\mathbb J_{2n}^T \hat e_i)$ for $i\leq k$ and $\alpha_i = \Omega_{\mathbb J_{2n}}(z,\hat e_i)$ for $i>k$, where $\hat e_i$ is the $i$th column vector of $B_{2k}$. Furthermore, we take 
\begin{equation}
	\hat e_{k+1} = \hat z / \| \hat z \|_2, \quad \hat z = w + B_{2k} \alpha,
\end{equation}
as the next enrichment vector to construct
\begin{equation}
	B_{2(k+1)} = [ \hat e_1 | \dots | \hat e_{k+1} | \mathbb J_{2n}^T \hat e_1 | \dots | \mathbb J_{2n}^T \hat e_{k+1} ].
\end{equation}
One can recover $e_{k+1}$ form the relation $e_{k+1} = X^{-1/2} \hat e_{k+1}$. However, since we are interested in the matrix $A_{2(k+1)}$ and not $\tilde A_{2(k+1)}$, we can solve the system $XA_{2(k+1)} = B_{2(k+1)}$ for $A_{2(k+1)}$. This procedure eliminates the computation of $X^{1/2}$.

For identifying the best vectors to be added to a set of basis vectors, we may use similar error functions to those introduced in \cref{sec:mor.3}. The projection error can be used to identify the snapshot that is worst approximated by a given basis $\tilde A_{2k}$:
\begin{equation} \label{eq:normmor.14}
\begin{aligned}
	z_{k+1} &:= \underset{z\in\{ z(t_i)\}_{i=1}^{N}}{\text{argmax } }\| z - P(z) \|_X.
\end{aligned}
\end{equation}
Where $P$ is defined in (\ref{eq:normmor.1}). Alternatively we can use the loss in the Hamiltonian function in (\ref{eq:mor.16}) for parameter dependent problems. We summarize the greedy method for generating a $J_{2n}$-symplectic matrix in \Cref{alg:2}.

\begin{algorithm} 
\caption{The greedy algorithm for generation of a $J_{2n}$-symplectic basis} \label{alg:2}
{\bf Input:} Tolerated projection error $\delta$, initial condition $ z_0$, the snapshots $\mathcal Z = \{Xz(t_i)\}_{i=1}^{N}$, full rank matrix $X=X^T>0$
\begin{enumerate}
\item $z_1 = Xz(0)$
\item $P = A \mathbb J_{2k}^T A^T X \mathbb J_{2n}$
\item $\hat e_1 \leftarrow z_1/ \| z_1 \|_2$
\item $B \leftarrow [\hat e_1| \mathbb J_{2n}^T \hat e_1]$
\item $k \leftarrow 1$
\item \textbf{while} $\| z - Pz\|_X > \delta$ for any $z \in \mathcal Z$
\item \hspace{0.5cm} $z_{k+1} := \underset{z\in \mathcal Z}{\text{argmax }} \| z - Pz \|_X$
\item \hspace{0.5cm} $\mathbb J_{2n}$-orthogonalize $z_{k+1}$ to obtain $\hat e_{k+1}$
\item \hspace{0.5cm} $B \leftarrow [\hat e_1|\dots |\hat e_{k+1} | \mathbb J_{2n}^T \hat e_1|\dots| \mathbb J_{2n}^T  \hat e_{k+1}]$
\item \hspace{0.5cm} $k \leftarrow k+1$
\item \textbf{end while}
\item solve $X A = B$ for $A$
\end{enumerate}
\vspace{0.5cm}
{\bf Output:} The reduced basis $A$
\end{algorithm}
It is shown in \cite{doi:10.1137/17M1111991} that under natural assumptions on the solution manifold of (\ref{eq:mor.8}), the original greedy method for symplectic basis generation converges exponentially fast. We expect the generalized greedy method, equipped with the error function (\ref{eq:normmor.14}), to converge as fast, since the $X$-norm is topologically equivalent to the standard Euclidean norm \cite{friedman1970foundations}, for a full rank matrix $X$.

\subsection{Efficient evaluation of nonlinear terms} \label{sec:normmor.3}
The evaluation of the nonlinear term in (\ref{eq:normmor.8}) still retains a computational complexity proportional to the size of the full order system (\ref{eq:mor.8}). To overcome this, we take an approach similar to \cref{sec:mor.2}. The DEIM approximation of the nonlinear term in (\ref{eq:normmor.8}) yields
\begin{equation} \label{eq:normmor.15}
	\dot y = J_{2k} A^TLAy + \tilde A ^+ X^{1/2} \mathbb J_{2n} U (\mathcal P^TU)^{-1}\mathcal  P^T \nabla_z f(Ay).
\end{equation}
Here $U$ is a basis constructed from the nonlinear snapshots $\{\nabla_z f(z(t_i))\}_{i=1}^N$, and $\mathcal P$ is the interpolating index matrix \cite{Chaturantabut:2010cz}. As discussed in \cref{sec:mor.2}, for a general choice of $U$, the reduced system (\ref{eq:normmor.8}) does not retain a Hamiltonian form. Since $(\tilde A^+ X^{1/2}) A = I_{2k}$ applying the chain rule on (\ref{eq:normmor.15}) yields
\begin{equation} \label{eq:normmor.16}
	\dot y = J_{2k} A^TLAy + \tilde A ^+ X^{1/2} \mathbb J_{2n} U (\mathcal P^TU)^{-1} \mathcal P^T (\tilde A^+ X^{1/2})^T \nabla_y f(Ay).
\end{equation}
Freedom in the choice of the basis $U$ allows us to require $U = X^{1/2} (\tilde A^+)^T$. This reduces the complex expression in (\ref{eq:normmor.16}) to
\begin{equation} \label{eq:normmor.17}
	\dot y = J_{2k} A^TLAy + J_{2k} \nabla_y f(Ay),
\end{equation}
and hence we recover the Hamiltonian structure. The reduced system then yields
\begin{equation} \label{eq:normmor.18}
\left\{
\begin{aligned}
	\dot y(t) &= J_{2k} A^TLAy + J_{2k} (\mathcal P^TX \mathbb J_{2n} X A \mathbb J_{2k})^{-1} \mathcal P^T \nabla_z f(z), \\
	y(0) &= \mathbb J_{2k}^T A^T X J X z_0.
\end{aligned}
\right.
\end{equation}
We now discuss how to ensure that $X^{1/2} (\tilde A^+)^T$ is a basis for the nonlinear snapshots. Note that if $z \in \text{colspan}\left(X^{1/2} (\tilde A^+)^T\right)$ then $X^{-1/2} z \in \text{colspan}\left(( \tilde A^+)^T \right)$. Therefore, it is sufficient to require $(\tilde A^+)^T$ to be a basis for $\{X^{-1/2} \nabla_z f(z(t_i))\}_{i=1}^N$. \Cref{thm:2} suggests that $(\tilde A^+)^T$ is a $J_{2n}^{-1}$-symplectic basis and that the transformation between $\tilde A$ and $(\tilde A^+)^T $ does not affect the symplectic feature of the bases. Consequently, from $A$ we may compute $(\tilde A^+)^T$ and enrich it with snapshots $\{X^{-1/2} \nabla_z f(z(t_i))\}_{i=1}^N$. Once $(\tilde A^+)^T$ represents the nonlinear term with the desired accuracy, we may compute $\tilde A= \left( \left( ( \tilde A^+ )^T \right)^+ \right)^T$ to obtain the reduced basis for (\ref{eq:normmor.18}). \Cref{thm:2} implies that $(\tilde A^+)^T$ is ortho-normal with respect to the $X^{-1}$-norm. This affects the ortho-normalization process. We note that greedy approaches to basis generation do not generally result in a minimal basis.

As discussed in \cref{sec:normmor.2} it is desirable to eliminate the computation of $X^{\pm 1/2}$. Having $z \in \text{colspan}\left(X^{1/2} (\tilde A^+)^T\right)$ implies that $X^{-1} z \in \text{colspan}(\mathbb J_{2n}^T X A \mathbb J_{2n})$. Note that \Cref{alg:2} constructs a $\mathbb J_{2n}$-symplectic matrix $XA$ and $\mathbb J_{2n}^T X A \mathbb J_{2n}$ is the symplectic inverse of $XA$ with respect to the standard symplectic matrix $\mathbb J_{2n}$. Given $e$ as a candidate for enriching $X^{1/2} (\tilde A^+)^T$ we may instead enrich $\mathbb J_{2n}^T X A \mathbb J_{2n}$ with $\hat e$, that solves $X \hat e = e$.

Since  $\mathbb J_{2n}^T X A \mathbb J_{2n}$ is $\mathbb J_{2n}$-symplectic the projection operator onto the column span of $\mathbb J_{2n}^T X A \mathbb J_{2n}$ can be constructed as $Q=\mathbb J_{2n}^T X A \mathbb J_{2n}A^TX$. Given a nonlinear snapshot $z$, we may need to project the vector $X^{-1}z$ onto colspan$(\mathbb J_{2n}^T X A \mathbb J_{2n})$. However, $Q(X^{-1}z)=\mathbb J_{2n}^T X A \mathbb J_{2n}A^Tz$ and thus, the matrix $X^{-1}$ does not appear explicitly. This process eliminates the computation of $X^{\pm 1/2}$. We summarize the process of generating a basis for the nonlinear terms in \Cref{alg:3}.

\begin{algorithm} 
\caption{Generation of a basis for nonlinear terms} \label{alg:3}
{\bf Input:} Tolerated projection error $\delta$, $\mathbb J_{2n}$-symplectic basis $B = X A$ of size $2k$, the snapshots $\mathcal G = \{ \nabla_zf(z(t_i))\}_{i=1}^{N}$, full rank matrix $X=X^T>0$
\begin{enumerate}
\item $Q \leftarrow \mathbb J_{2n}^T X A \mathbb J_{2n}A^T$
\item compute $(B^+)^T = \mathbb J_{2n}^T B \mathbb J_{2n} = [e_1|\dots |e_{k} | \mathbb J_{2n}^Te_1|\dots| \mathbb J_{2n}^Te_{k}]$
\item \textbf{while} $\| g - Q g \|_2 > \delta$ for any $g \in \mathcal G$
\item \hspace{0.5cm} $g_{k+1} := \underset{g\in \mathcal G}{\text{argmax }} \| g -  Q g  \|_2$
\item \hspace{0.5cm} solve $X e = g_{k+1}$ for $e$
\item \hspace{0.5cm} $\mathbb J_{2n}$-orthogonalize $e$ to obtain $e_{k+1}$
\item \hspace{0.5cm} $(B^+)^T \leftarrow [e_1|\dots |e_{k+1} | \mathbb J_{2n}^Te_1|\dots| \mathbb J_{2n}^Te_{k+1}]$
\item \hspace{0.5cm} $k \leftarrow k+1$
\item \textbf{end while}
\item compute $XA = \left( \left (B^+)^T \right)^+ \right)^T$
\end{enumerate}
\vspace{0.5cm}
{\bf Output:} $\mathbb J_{2n}$-symplectic basis $XA$
\end{algorithm}

\subsection{Offline/online decomposition} \label{sec:normmor.4}
Model order reduction becomes particularly useful for parameter dependent problems in multi-query settings. For the purpose the of most efficient computation, it is important to delineate high dimensional ($\mathcal{O}(n^{\alpha})$) offline computations from low dimensional ($\mathcal{O}(k^{\alpha})$) online ones, for some $\alpha \in \mathbb N$. Time intensive high dimensional quantities are computed only once for a given problem in the offline phase and the cheaper low dimensional computations can be performed in the online phase. This segregation or compartmentalization of quantities, according to their computational cost, is referred to as the offline/online decomposition.

More precisely, one can decompose the computations into the following stages:
\emph{Offline stage:} Quantities in this stage are computed only once and then used in the online stage.
\begin{enumerate}
\item Generate the weighted snapshots $\{ X z(t_i) \}_{i=1}^N$ and the snapshots of the nonlinear term $\{\nabla_zf(z(t_i))\}_{i=1}^N$
\item Generate a $J_{2n}$-symplectic basis for the solution snapshots and the snapshots of the nonlinear terms, following \Cref{alg:2,alg:3}, respectively.
\item Assemble the reduced order model \cref{eq:normmor.18}.
\end{enumerate}
\emph{Online stage:} The reduced model \cref{eq:normmor.18} is solved for multiple parameter sets and the output is extracted.
