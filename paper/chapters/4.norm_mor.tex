\section{Symplectic model-reduction with a weighted inner product} \label{sec:normmor}

In this section we combine the concept of model reduction with a weighted inner product, discussed in \Cref{sec:mor.1}, with the symplectic model reduction discussed in \Cref{sec:mor.2}. We will argue that the new method can be viewed as a natural extension of the original symplectic method. Finally we generalize the greedy method for the symplectic basis generation, and the symplectic model reduction of nonlinear terms to be compatible with any weighted inner product.

\subsection{Generalization of the symplectic projection} \label{sec:normmor.1}
As discussed in \Cref{sec:mor.1}, the error analysis of methods for solving partial differential equations often require the use of a weighted inner product. This is particularly important when dealing with Hamiltonian systems, where the system energy can induce a norm that is fundamental to the dynamics of the system.

Consider a Hamiltonian system of the form (\ref{eq:mor.8}) together with the weighted inner product defined in (\ref{eq:mor.3}) with $m=2n$. Also suppose that the solution $z$ to (\ref{eq:mor.8}) is well approximated by a $2k$ dimensional symplectic subspace with the basis $A$. We seek to construct a projection operator that minimizes the projection error with respect to the $X$-norm while preserving the symplectic dynamics of (\ref{eq:mor.8}) in the projected space. Consider the operator $P: \mathbb R^{2n} \to \mathbb R^{2n}$ defined as
\begin{equation} \label{eq:normmor.1}
	P = A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X.
\end{equation}
It is easy to show that $P$ is idempotent if and only if
\begin{equation} \label{eq:normmor.2}
	\mathbb J_{2k}^T A^T X \mathbb J_{2n} X A = I_{2k}.
\end{equation}
In which case $P$ is a projection operator onto colspan$(A)$. Suppose that $S$ is the snapshot matrix containing the time samples $\{z(t_i)\}_{i=1}^N$ of the solution to (\ref{eq:mor.8}). We seek to find the basis $A$ That minimizes the collective projection error of snapshots with respect to the $X$-norm,
\begin{equation} \label{eq:normmor.3}
\begin{aligned}
& \underset{A\in \mathbb{R}^{2n\times 2k}}{\text{minimize}}
& & \sum_{i=1}^N \| z(t_i) - P(z(t_i)) \|_X^2, \\
& \text{subject to}
& & \mathbb J_{2k}^T A^T X \mathbb J_{2n} X A = I_{2k}.
\end{aligned}
\end{equation}
By (\ref{eq:normmor.1}) we have
\begin{equation} \label{eq:normmor.4}
\begin{aligned}
	\sum_{i=1}^N \| z(t_i) - P(z(t_i)) \|_X^2 &= \sum_{i=1}^N \| z(t_i) - A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X z(t_i) \|_X^2 \\
	&= \sum_{i=1}^N \| X^{1/2}z(t_i) - X^{1/2} A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X z(t_i) \|_2^2 \\
	&= \| X^{1/2} S - X^{1/2} A \mathbb J_{2k}^T A^T X \mathbb J_{2n} X S \|_F^2 \\
	&= \| \tilde S - \tilde A \tilde A ^+ \tilde S \|_F^2.
\end{aligned}
\end{equation}
Here $S$ is the matrix of samples $\{ z(t_i) \}_{i=1}^{N}$ in its columns, $\tilde S = X^{1/2} S$, $\tilde A = X^{1/2} A$ and $\tilde A^+ = \mathbb J_{2k}^T \tilde A^T J_{2n}$ is the symplectic inverse of $\tilde A$ with respect to the skew-symmetric matrix $J_{2n} = X^{1/2} \mathbb J_{2n} X^{1/2}$. Note that the symplectic inverse in (\ref{eq:normmor.4}) is a generalization of the symplectic inverse introduced in \Cref{sec:mor.2}. Therefore, we may use the same notation (the superscript $+$) for both. We summarized the properties of this generalization in \Cref{thm:2}. With this notation, the condition (\ref{eq:normmor.2}) turns into $\tilde A ^+ \tilde A = I_{2k}$ which is equivalent to $\tilde A ^T J_{2n} \tilde A = \mathbb J_{2k}$. In other words, this condition implies that $\tilde A$ has to be a $J_{2n}$-symplectic matrix. Finally we can rewrite the minimization (\ref{eq:normmor.3}) as
\begin{equation} \label{eq:normmor.5}
\begin{aligned}
& \underset{\tilde A\in \mathbb{R}^{2n\times 2k}}{\text{minimize}}
& & \| \tilde S - P^\text{symp}_{X,\tilde A}(\tilde S) \|_F, \\
& \text{subject to}
& & \tilde A^T J_{2n} \tilde A = \mathbb J_{2k}.
\end{aligned}
\end{equation}
where $P^\text{symp}_{X,\tilde A} = \tilde A \tilde A^+$ is the symplectic projection with respect to the $X$-norm onto the span of $\tilde A$. At first glance, the minimization (\ref{eq:normmor.5}) might look similar to (\ref{eq:mor.13}). However, since $\tilde A$ is $J_{2n}$-symplectic, and the projection operator depends on $X$, we need to seek an alternative approach to find a near optimal solution to (\ref{eq:normmor.5}). 

As (\ref{eq:mor.13}), direct approaches to solving (\ref{eq:normmor.5}) are impractical. Furthermore, there are no SVD-type methods known to the authors, that solve (\ref{eq:normmor.5}). However, the greedy generation of the symplectic basis can be generalized to generate a near optimal basis $\tilde A$. The generalized greedy method is discussed in \Cref{sec:normmor.2}.

Now suppose that a basis $A=X^{-1/2}\tilde A$, with $\tilde A$ solving (\ref{eq:normmor.5}), is available such that $z \approx Ay$ with $y\in \mathbb R^{2k}$, the expansion coefficients of $z$ in the basis of $A$. Using (\ref{eq:normmor.2}) we may write the reduced system to (\ref{eq:mor.8}) as
\begin{equation} \label{eq:normmor.6}
	\dot y = \mathbb J_{2k}^T A^T X \mathbb J_{2n} X \mathbb{J}_{2n} LAy + \mathbb J_{2k}^T A^T X \mathbb J_{2n} X \mathbb{J}_{2n} \nabla_z f(Ay).
\end{equation}
Since $(\mathbb J_{2k}^T A^T X \mathbb J_{2n} X) A = I_{2k}$, we may use the chain rule to write
\begin{equation} \label{eq:normmor.7}
	\nabla_z H(z) = ( \mathbb J_{2k}^T A^T X \mathbb J_{2n} X )^T \nabla_y H(Ay).
\end{equation}
Finally, as $\nabla_z H(z) = Lz + \nabla_z f(z)$, the reduced system (\ref{eq:normmor.6}) becomes
\begin{equation} \label{eq:normmor.8}
\left\{
\begin{aligned}
	\dot y(t) &= J_{2k} A^T L A y + J_{2k} \nabla_y f(Ay), \\
	y(0) &= \tilde A^+ X^{1/2} z_0,
\end{aligned}
\right.
\end{equation}
where $J_{2k}=\tilde A^+ J_{2n} (\tilde A^+)^T$ is a skew-symmetric matrix. The system (\ref{eq:normmor.8}) is a generalized Hamiltonian system with the Hamiltonian defined as $\tilde H(y) = \frac 1 2 y^TA^TLAy + f(Ay)$. Therefore, a Poisson integrator preserves the symplectic symmetry associated with (\ref{eq:normmor.8}). 


We close this section by summarizing the properties of the symplectic inverse in the following theorem.
\begin{theorem} \label{thm:2}
Let $A\in \mathbb R^{2n\times 2k}$ be a $J_{2n}$-symplectic basis where $J_{2n}\in\mathbb R^{2n}$ is a full rank and skew-symmetric matrix. Furthermore, suppose that $A^{+} = \mathbb{J}_{2k}^T A^T J_{2n}$ is the symplectic inverse. Then the following holds:
\begin{enumerate}
\item $A^+A = I_{2k}$.
\item $(A^+)^T$ is $J_{2n}^{-1}$-symplectic.
\item $\left(\left(\left(A^+\right)^T\right)^+\right)^T = A$.
\item Let $J_{2n}=X^{1/2}\mathbb J_{2n} X^{1/2}$. Then $A$ is ortho-normal with respect to the $X$-norm, if and only if $(A^+)^T$ is ortho-normal with respect to the $X^{-1}$-norm.
\end{enumerate}
\end{theorem}
\begin{proof}
It is straight forward to show all statements using the definition of a symplectic basis.
\end{proof}

\subsection{Greedy generation of a $J_{2n}$-symplectic basis} \label{sec:normmor.2}
In this section we modify the greedy algorithm introduced in \Cref{sec:mor.3} to construct a $J_{2n}$-symplectic basis. Ortho-normalization is an essential step in greedy approaches to basis generation \cite{hesthaven2015certified,quarteroni2015reduced}. Here, we summarize a variation of the GS orthogonalization process, known as the \emph{symplectic GS} process.

Suppose that $\Omega$ is a symplectic form defined on $\mathbb R^{2n}$ such that $\Omega(x,y) = x^T J_{2n} y$, for all $x,y\in \mathbb R^{2n}$ and some full rank and skew-symmetric matrix $J_{2n} = X^{1/2} \mathbb J_{2n} X^{1/2}$. We would like to build a basis of size $2k+2$ in an iterative manner and start with some initial vector, e.g. $e_1 = z_0$. It is known that a symplectic basis is even dimensional \cite{Marsden:2010:IMS:1965128}. We may take $Te_1$, where $T = X^{-1/2} \mathbb J_{2n}^{T}X^{1/2}$, as a candidate for the second basis vector. It is easily checked that $\tilde A_2=[e_1|Te_1]$ is $J_{2n}$-symplectic and consequently, $\tilde A_2$ is the first basis generated by the greedy approach. Next, suppose that $\tilde A_{2k} = [e_1|\dots|e_k|Te_1|\dots|Te_k]$ is generated in the $k$th step of the greedy method and $z\not \in \text{span}\left(\tilde A_{2k}\right)$ is provided. We aim to $J_{2n}$-orthogonalize $z$ with respect to the basis $\tilde A_{2k}$. This means we seek find coefficients $\alpha_i,\beta_i\in \mathbb R$, for $i=1,\dots,k$ such that
\begin{equation} \label{eq:normmor.9}
	\Omega\left( z +\sum_{i=1}^{k} \alpha_i e_i +\sum_{i=1}^{k} \beta_i Te_i, \sum_{i=1}^{k}\bar \alpha_i e_i +\sum_{i=1}^{k} \bar \beta_i Te_i \right) = 0,
\end{equation}
for all possible $\bar \alpha_i,\bar \beta_i \in \mathbb R$, $i=1,\dots,k$. It is easily checked that this problem has the unique solution
\begin{equation} \label{eq:normmor.10}
	\alpha_i = - \Omega(z,Te_i), \quad \beta = \Omega(z,e_i).
\end{equation}
If we take $\tilde z = z -\sum_{i=1}^{k} \Omega(z,Te_i) e_i +\sum_{i=1}^{k} \Omega(z,e_i) Te_i$, then the next candidate pair of basis vectors are $e_{k+1} = \tilde z / \| \tilde z \|_X$ and $Te_{k+1}$. Finally, the basis generated at the $(k+1)$-th step of the greedy method is given by
\begin{equation} \label{eq:normmor.11}
	\tilde A_{2k+2} = [e_1|\dots|e_k|e_{k+1}|Te_1|\dots|Te_k|Te_{k+1}].
\end{equation}
\Cref{thm:3} guarantees that the column vectors of $\tilde A_{2k+2}$ are linearly independent. Furthermore, it is checked easily that $\tilde A_{2k+2}$ is $J_{2n}$-symplectic. We note that the symplectic GS orthogonalization process is chosen due to its simplicity. However, in problems where there is a need for a large basis, this process might be impractical. In such cases, one may use a backward stable routine, e.g. the isotropic Arnoldi method or the isotropic Lanczos method \cite{doi:10.1137/S1064827500366434}.

It is well known that a symplectic basis, in general, is not norm bounded \cite{doi:10.1137/050628519}. The following theorem guarantees that the greedy method for generating a $J_{2n}$-symplectic basis yields a bounded basis.
\begin{theorem} \label{thm:3}
The basis generated by the greedy method for constructing a $J_{2n}$-symplectic basis is ortho-normal with respect to the $X$-norm.
\end{theorem}
\begin{proof}
Let $\tilde A_{2k}=[e_1|\dots,e_k|Te_1|\dots|Te_k]$ be the $J_{2n}$-symplectic basis generated at the $k$th step of the greedy method. Using the fact that $\tilde A_{2k}$ is $J_{2n}$-symplectic, one can check that
\begin{equation} \label{eq:normmor.12}
	[e_i,e_j]_X = [Te_i,Te_j]_X = \Omega(e_i,Te_j)=\delta_{i,j}, \quad i,j=1,\dots,k,	
\end{equation}
and
\begin{equation} \label{eq:normmor.13}
	[e_i,Te_j]_X = \Omega(e_i,e_j) = 0\quad i,j=1,\dots,k,
\end{equation}
where $\delta_{i,j}$ is the Kronecker delta function. This ensures that $\tilde A_{2k}^TX\tilde A_{2k} = I_{2k}$, i.e., $\tilde A_{2k}$ is an ortho-normal basis with respect to the $X$-norm.
\end{proof}
We note that if we take $X=I_{2n}$, then the greedy process generates a $\mathbb J_{2n}$- symplectic basis. With this choice, the greedy method discussed above becomes identical to the greedy process discussed in \Cref{sec:mor.3}, since $T = X^{-1/2}\mathbb J_{2n}^TX^{1/2} = \mathbb J_{2n}^T$.

For identifying the best vectors to be added to a set of basis vectors, we may use similar error functions to those introduced in \Cref{sec:mor.3}. The projection error can be used to identify the snapshot that is worst approximated by a given basis $\tilde A_{2k}$:
\begin{equation} \label{eq:normmor.14}
	z_{k+1} := \underset{z\in\{ z(t_i)\}_{i=1}^{N}}{\text{argmax } }\| X^{1/2}z - P^\text{symp}_{X,\tilde A_{2k}}(X^{1/2}z) \|_2. 
\end{equation}
Alternatively we can use the loss in the Hamiltonian function in (\ref{eq:mor.16}) for parameter dependent problems. We summarize the greedy method for generating a $J_{2n}$-symplectic matrix in \Cref{alg:2}.

\begin{algorithm} 
\caption{The greedy algorithm for generation of a $J_{2n}$-symplectic basis} \label{alg:2}
{\bf Input:} Tolerated projection error $\delta$, initial condition $ z_0$, the snapshots $\{\tilde z(t_i)\}_{i=1}^{N} = \{X^{1/2} z(t_i)\}_{i=1}^{N}$, full rank matrix $X=X^T>0$
\begin{enumerate}
\item $T \leftarrow X^{-1/2}\mathbb J_{2n}^T X^{1/2}$
\item $t^1 \leftarrow t=0$
\item $e_1 \leftarrow X^{1/2}z_0$
\item $\tilde A \leftarrow [e_1|Te_1]$
\item $k \leftarrow 1$
\item \textbf{while} $\| \tilde z(t) - P^\text{symp}_{X,\tilde A}( \tilde z(t) ) \|_2 > \delta$ for all $t \in [0,T]$
\item \hspace{0.5cm} $t^{k+1} := \underset{t\in [0,T]}{\text{argmax }} \| \tilde z(t) - P^\text{symp}_{X,\tilde A}( \tilde z(t) ) \|_2$
\item \hspace{0.5cm} $J_{2n}$-orthogonalize $ \tilde z(t^{k+1})$ to obtain $e_{k+1}$
\item \hspace{0.5cm} $\tilde A \leftarrow [e_1|\dots |e_{k+1} | Te_1|\dots| Te_{k+1}]$
\item \hspace{0.5cm} $k \leftarrow k+1$
\item \textbf{end while}
\item $A\leftarrow X^{-1/2} \tilde A$
\end{enumerate}
\vspace{0.5cm}
{\bf Output:} $J_{2n}$-symplectic basis $\tilde A$ and the reduced basis $A$
\end{algorithm}

It is shown in \cite{doi:10.1137/17M1111991} that under natural assumptions on the solution manifold of (\ref{eq:mor.8}), the original greedy method for symplectic basis generation converges exponentially fast. We expect the generalized greedy method, equipped with the error function (\ref{eq:normmor.14}), to converge as fast, since the $X$-norm is topologically equivalent to the standard Euclidean norm \cite{friedman1970foundations}, for a full rank matrix $X$.

\subsection{Efficient evaluation of nonlinear terms} \label{sec:normmor.3}
The evaluation of the nonlinear term in (\ref{eq:normmor.8}) still retains a computational complexity proportional to the size of the full order system (\ref{eq:mor.8}). To overcome this, we take an approach similar to \Cref{sec:mor.2}. The DEIM approximation of the nonlinear term in (\ref{eq:normmor.8}) yields
\begin{equation} \label{eq:normmor.15}
	\dot y = J_{2k} A^TLAy + \tilde A ^+ X^{1/2} \mathbb J_{2n} U (\mathcal P^TU)^{-1}\mathcal  P^T \nabla_z f(Ay).
\end{equation}
Here $U$ is a basis constructed from the nonlinear snapshots $\{\nabla_z f(z(t_i))\}_{i=1}^N$, and $\mathcal P$ is the interpolating index matrix \cite{Chaturantabut:2010cz}. As discussed in \cref{sec:mor.2}, for a general choice of $U$, the reduced system (\ref{eq:normmor.8}) does not retain a Hamiltonian form. Since $(\tilde A^+ X^{1/2}) A = I_{2k}$ applying the chain rule on (\ref{eq:normmor.15}) yields
\begin{equation} \label{eq:normmor.16}
	\dot y = J_{2k} A^TLAy + \tilde A ^+ X^{1/2} \mathbb J_{2n} U (\mathcal P^TU)^{-1} \mathcal P^T (\tilde A^+ X^{1/2})^T \nabla_y f(Ay).
\end{equation}
If we require $U = X^{1/2} (\tilde A^+)^T$ then the complex expression in (\ref{eq:normmor.16}) reduces to
\begin{equation} \label{eq:normmor.17}
	\dot y = J_{2k} A^TLAy + J_{2k} \nabla_y f(Ay),
\end{equation}
and hence we recover the Hamiltonian structure. This yields the reduced system
\begin{equation} \label{eq:normmor.18}
\left\{
\begin{aligned}
	\dot y(t) &= J_{2k} A^TLAy + J_{2k} (\mathcal P^TX^{1/2} (\tilde A^+)^T)^{-1} \mathcal P^T \nabla_z f(z), \\
	y(0) &= \tilde A^+ X^{1/2} z_0.
\end{aligned}
\right.
\end{equation}
We now discuss how to ensure that $X^{1/2} (\tilde A^+)^T$ is a basis for the nonlinear snapshots. Note that if $z \in \text{span}\left(X^{1/2} (\tilde A^+)^T\right)$ then $X^{-1/2} z \in \text{span}\left(( \tilde A^+)^T \right)$. Therefore, it is sufficient to require $(\tilde A^+)^T$ to be a basis for $\{X^{-1/2} \nabla_z f(z(t_i))\}_{i=1}^N$. \Cref{thm:2} suggests that $(\tilde A^+)^T$ is a $J_{2n}^{-1}$-symplectic basis and that the transformation between $\tilde A$ and $(\tilde A^+)^T $ does not affect the symplectic feature of the bases. Consequently, from $A$ we may compute $(\tilde A^+)^T$ and enrich it with snapshots $\{X^{-1/2} \nabla_z f(z(t_i))\}_{i=1}^N$. Once $(\tilde A^+)^T$ represents the nonlinear term with the desired accuracy, we may compute $\tilde A= \left( \left( ( \tilde A^+ )^T \right)^+ \right)^T$ to obtain the reduced basis for (\ref{eq:normmor.18}). Note that \Cref{thm:2} implies that $(\tilde A^+)^T$ is ortho-normal with respect to the $X^{-1}$-norm. This affects the ortho-normalization process. We summarized the process of generating a basis for the nonlinear terms in \Cref{alg:3}.

\begin{algorithm} 
\caption{Generation of a basis for nonlinear terms} \label{alg:3}
{\bf Input:} Tolerated projection error $\delta$, $J_{2n}$-symplectic basis $\tilde A$ of size $2k$, the snapshots $\{\tilde z(t_i)\}_{i=1}^{N} = \{X^{-1/2} \nabla_zf(z(t_i))\}_{i=1}^{N}$, full rank matrix $X=X^T>0$
\begin{enumerate}
\item $T \leftarrow X^{1/2}\mathbb J_{2n}^T X^{-1/2}$
\item compute $(\tilde A^+)^T$
\item \textbf{while} $\| \tilde z(t) - P^\text{symp}_{X^{-1},(\tilde A^+)^T}( \tilde z(t) ) \|_2 > \delta$ for all $t \in [0,T]$
\item \hspace{0.5cm} $t^{k+1} := \underset{t\in [0,T]}{\text{argmax }} \| \tilde z(t) - P^\text{symp}_{X^{-1},(\tilde A^+)^T}( \tilde z(t) ) \|_2$
\item \hspace{0.5cm} $J_{2n}^{-1}$-orthogonalize $ \tilde z(t^{k+1})$ to obtain $e_{k+1}$
\item \hspace{0.5cm} $(\tilde A^+)^T \leftarrow [e_1|\dots |e_{k+1} | Te_1|\dots| Te_{k+1}]$
\item \hspace{0.5cm} $k \leftarrow k+1$
\item \textbf{end while}
\item $\tilde A \leftarrow \left( \left( ( \tilde A^+ )^T \right)^+ \right)^T$
\end{enumerate}
\vspace{0.5cm}
{\bf Output:} $J_{2n}$-symplectic basis $\tilde A$
\end{algorithm}

\subsection{Offline/online decomposition} \label{sec:normmor.4}
Model order reduction becomes particularly useful for parameter dependent problems in multi-query settings. For the purpose the of most efficient computation, it is important to delineate high dimensional ($\mathcal{O}(n^{\alpha})$) offline computations from low dimensional ($\mathcal{O}(k^{\alpha})$) online ones, for some $\alpha \in \mathbb N$. Time intensive high dimensional quantities are computed only once for a given problem in the offline phase and the cheaper low dimensional computations can be performed in the online phase. This segregation or compartmentalization of quantities, according to their computational cost, is referred to as the offline/online decomposition.

More precisely, one can decompose the computations into the following stages:
\emph{Offline stage:} Quantities in this stage are computed only once and then used in the online stage.
\begin{enumerate}
\item Generate the weighted snapshots $\{ X^{1/2} z(t_i) \}_{i=1}^N$ and the weighted snapshots of the nonlinear term $\{X^{-1/2}. \nabla_zf(z(t_i))\}_{i=1}^N$
%\item Generate weighted snapshots matrix $X^{1/2}S$ and basis $U$ of nonlinear snapshots $\{\nabla_zf(z(t_i))\}_{i=1}^N$ by solving the high dimensional system \cref{eq:mor.8}.
\item Generate a $J_{2n}$-symplectic basis for the solution snapshots and the snapshots of the nonlinear terms, following \Cref{alg:2,alg:3}, respectively.
\item Assemble the reduced order model \cref{eq:mor.12}.
\end{enumerate}
\emph{Online stage:} the reduced model \cref{eq:mor.12} is solved for multiple parameter sets and the output is extracted.
